{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6 - Classifiers Boosting Algorithms\n",
    "\n",
    "In this lab, we will implement the AdaBoost algorithm as an ensemble learning technique which\n",
    "aims to combine a number of weak classifiers to yield a strong classifier at the end.\n",
    "The idea of this lab is to identify whether a tumor with given characteristics is malignant or\n",
    "benign. This is a two-class classification problem.\n",
    "\n",
    "## Dataset and Features\n",
    "\n",
    "You will be working on the dataset from *Hastie et al,* for breast tumor classification with 10 features representing the tumor's:\n",
    "\n",
    "                              1. Area            6. Texture\n",
    "                              2. Perimeter       7. Symmetry\n",
    "                              3. Radius          8. Greyscale Level\n",
    "                              4. Compactness     9. Fractal Dimension\n",
    "                              5. Concavity      10. Coastline Approximation.\n",
    "There is one output variable which is diagnosis. It takes one of two values `+1` for malignant and `-1` for benign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1:\n",
    "Why it is sometimes better to have the two class values `+1` and `-1` instead of `+1`\n",
    "and `0`?\\\n",
    "**HINT :** Think about the voting scheme at the end of the boosting algorithm. How can the class values\n",
    "affect this scheme?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Your answer: \\n    because it allows for a clearer distinction between the two classes. With \"+1\" and \"-1\", the two classes are clearly\\n    defined as positive and negative, respectively, and there is no ambiguity about how to interpret the values.\\n    \\n    using \"+1\" and \"-1\" can simplify the mathematical operations involved in classification algorithms. \\n    For example, in binary classification using a linear classifier, the decision boundary is a hyperplane \\n    that separates the positive and negative classes. Using \"+1\" and \"-1\" allows this hyperplane to be defined \\n    as a linear equation with a simple threshold, whereas using \"+1\" and \"0\" would require a more complex threshold function.\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Your answer: \n",
    "    because it allows for a clearer distinction between the two classes. With \"+1\" and \"-1\", the two classes are clearly\n",
    "    defined as positive and negative, respectively, and there is no ambiguity about how to interpret the values.\n",
    "    \n",
    "    using \"+1\" and \"-1\" can simplify the mathematical operations involved in classification algorithms. \n",
    "    For example, in binary classification using a linear classifier, the decision boundary is a hyperplane \n",
    "    that separates the positive and negative classes. Using \"+1\" and \"-1\" allows this hyperplane to be defined \n",
    "    as a linear equation with a simple threshold, whereas using \"+1\" and \"0\" would require a more complex threshold function.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement\n",
    "You are required to fill the function `adaboost_classifier(Y_train, X_train, Y_test, X_test, T, clf).`\\\n",
    "This function takes as parameters:\n",
    "\n",
    "| | |\n",
    "|:---|:-|\n",
    "| **Y_train**| The target values for the training set |\n",
    "| **X_train**| The input features for the training set.|\n",
    "| **Y_test**| The target values for the test set.|\n",
    "| **Y_train**| The input features for the training set.|\n",
    "| **T**| The number of iterations of the AdaBoost Algorithm.|\n",
    "| **clf**| The classifier to be used. (In our case, we are using a decision tree stump as a base classifier). You can use any other classifier.|\n",
    "\n",
    "This function should return two values:\n",
    "- The accuracy of the model on the training set.\n",
    "- The accuracy of the model on the test set.\n",
    "\n",
    "\n",
    "#### Fair Note:\n",
    "In the explanation video, we assumed that (T) is the number of models you want to fit. However, this is not always the case. You may have a model base (like here we have decision trees) and you are allowed to use as many of it as you can. So (T) here becomes the number of iterations where your goal is to enhance the performance with as few iterations as possible. \n",
    "\n",
    "Do not get confused:\n",
    "- If your case is you have T models only, we set T = number of models to fit.\n",
    "- If you are allowed to use as many models as you can (as many decision trees as you need), then T is the number of iterations to choose. In such case, T becomes a parameter controlled by the programmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imports ##\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "\n",
    "import math\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** we prepared some utility functions to help you throughout the lab. please go and check the file *utils.py* and make sure you understand each function and know how to use it.\n",
    "\n",
    "### TODO: AdaBoost Implementation\n",
    "\n",
    "AdaBoost is an iterative algorithm that gives weights for the best classifier every iteration, updates weights of the data points, then repeats until convergence.\n",
    "\n",
    "The steps of the algorithm are:\n",
    "\n",
    "1. Initialize weights of the training examples:\n",
    "\n",
    "$$w_{m} = \\frac {1}{M}, m = 1,2,...M$$\n",
    "\n",
    "                                        M: number of training examples. \n",
    "\n",
    "2. For t=1 to $T$:\n",
    "\n",
    "    a) Select a classifier $h_{t}$ that best fits to the training data using weights $w_{m}$ of the training examples.\n",
    "\n",
    "    b) Compute error of $h_{t}$ as:\n",
    "$$err_{t} = \\frac {\\Sigma_{m=1}^{M} w_{m} \\phi (c_{m} \\neq h_{t}(x_{m}))}{\\Sigma_{m=1}^{M} w_{m}}$$\n",
    "\n",
    "    c) Compute weight of classifier:\n",
    "$$\\alpha_{t} = \\log (\\frac {1-err_{t}}{err_{t}} )$$\n",
    "\n",
    "    d) Update weights of wrongly classified examples:\n",
    "$$w_{m} = w_{m} * \\exp^{\\alpha_{t} \\phi (c_{m} \\neq h_{t}(x_{m}))}, \\space m = 1 ... M$$\n",
    "\n",
    "    e) Renormalize weights $w_{m}$\n",
    "\n",
    "\n",
    "\\\n",
    "3. Output: $C(x)= argmax_{k}\\space (\\space \\Sigma_{t=1}^{T} \\alpha_{t} * \\phi (h_{t}(x) = k)) \\space)$\n",
    "\n",
    "**Where** in step 2.B and 2.D, the $\\phi (y)$ function is called the *miss indicator* function that gives values:\n",
    "\n",
    "                                     1: if y is True\n",
    "                                     0: if y is False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaboost_classifier(Y_train, X_train, Y_test, X_test, T, clf):\n",
    "    \n",
    "    #TODO: FILL THE FUNCTION with the implementation as the steps above\n",
    "\n",
    "    # TODO [1]: Initialize weights\n",
    "    w = np.ones(9600)* (1/len(X_train))\n",
    "\n",
    "    ## TODO [2]:  Initialize the training and test data with empty array placeholders\n",
    "    #### Hint: what should be their shape?\n",
    "    pred_train = np.empty(shape = [T, len(X_train)])  ## predicted classes of the training examples\n",
    "    pred_test = np.empty(shape = [T, len(X_test)])   ## predicted classes of the test examples\n",
    "\n",
    "    ## TODO [3]: loop over the boosting iterations \n",
    "    for i in range(T): \n",
    "\n",
    "        # TODO [4]: Fit a classifier with the specific weights \n",
    "        ## TODO [4.A]: fit the classifier on the training data\n",
    "        #### Hint: search how sklearn.tree.DecisionTreeClassifier fits classifier on data\n",
    "        ### Hint: search for parameter weights in the fit matrix\n",
    "        model = clf.fit(X_train, Y_train, w)\n",
    "        \n",
    "        # TODO [4.B]: predict classes for the training data and test data\n",
    "        pred_train_i = model.predict(X_train) \n",
    "        pred_test_i = model.predict(X_test)\n",
    "        \n",
    "        # TODO [5]: calculate the miss Indicator function\n",
    "        arr_train = (pred_train_i != Y_train)\n",
    "        \n",
    "        # TODO [6]: calculate the error for the current classifier (err_t)\n",
    "        err_t = np.sum(w*arr_train) / np.sum(w)\n",
    "        \n",
    "        # TODO [7]: calculate current classifier weight (Alpha_t)\n",
    "        alpha_t = np.log((1-err_t) / err_t)\n",
    "        \n",
    "        # TODO [8]: update the weights \n",
    "        w = w*np.exp(alpha_t*arr_train)\n",
    "        \n",
    "        # TODO [9] Add to the overall predictions\n",
    "        pred_train[i] = pred_train_i * alpha_t\n",
    "        pred_test[i] = pred_test_i * alpha_t\n",
    "\n",
    "\n",
    "    pred_train_final = np.sum(pred_train, axis=0)\n",
    "    pred_test_final = np.sum(pred_test, axis=0)\n",
    "        \n",
    "    # TODO [10]: Return error rate in train and test set\n",
    "    #### Hint: use function get_accuracy from utils.py\n",
    "    train_error = utils.get_accuracy(np.where(pred_train_final > 0, 1, -1), Y_train)\n",
    "    test_error = utils.get_accuracy(np.where(pred_test_final > 0, 1, -1), Y_test)\n",
    "    return train_error, test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Boosted Classifier\n",
    "\n",
    "Now we will use the function you implemented to build a classifer.\\\n",
    "You will not change code here, only read the code below and run it to see how **AdaBoost** enhanced the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data ...\n",
      "Number of Iterations :  10\n",
      "Number of Iterations :  60\n",
      "Number of Iterations :  110\n",
      "Number of Iterations :  160\n",
      "Number of Iterations :  210\n",
      "Number of Iterations :  260\n",
      "Number of Iterations :  310\n",
      "Number of Iterations :  360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\Documents\\GitHub\\neural-network-labs\\Lab 6 - AdaBoost Classifier\\utils.py:20: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  plot1.set_xticklabels(range(0, 450, 50))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### DO NOT CHANGE CODE ####\n",
    "\n",
    "## First, read the dataset\n",
    "x,y = make_hastie_10_2()\n",
    "df = pd.DataFrame(x)\n",
    "df['Y'] = y\n",
    "print('Reading Data ...')\n",
    "\n",
    "# Split into training and test set\n",
    "train, test = train_test_split(df, test_size=0.2) # this function shuffles the data points, and splits the data into\n",
    "                                                  # 80% training set and 20% test set (indicated by test_size=0.2)\n",
    "\n",
    "\n",
    "X_train, Y_train = train.iloc[:, :-1], train.iloc[:, -1]\n",
    "X_test, Y_test = test.iloc[:, :-1], test.iloc[:, -1]\n",
    "# Fit a simple decision tree first\n",
    "clf_tree = DecisionTreeClassifier(max_depth=1, random_state=1)\n",
    "\n",
    "# Fit Adaboost classifier using a decision tree as base estimator\n",
    "# Test with different number of iterations\n",
    "acc_train, acc_test = [],[]\n",
    "x_range = range(10, 410, 50)\n",
    "for i in x_range:\n",
    "    print('Number of Iterations : ' , i)\n",
    "    acc_i = adaboost_classifier(Y_train, X_train, Y_test, X_test, i, clf_tree)\n",
    "    acc_train.append(acc_i[0])\n",
    "    acc_test.append(acc_i[1])\n",
    "\n",
    "# Compare error rate vs number of iterations\n",
    "utils.plot_accuracy(acc_train, acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2:\n",
    "Justify why the plot is the way it is (is it increasing or decreasing? why? when does it flattens out?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Your answer:\\n    the plot is increasing the more iterations we provide the accurate target values we got\\n    as adaboosta algorithm depends on finding the best fitting of a classifier on a data with different weights of data points in each iteration it does\\n    then sum up all those good classifiers to obtain one strong classifier over the data\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Your answer:\n",
    "    the plot is increasing the more iterations we provide the accurate target values we got\n",
    "    as adaboosta algorithm depends on finding the best fitting of a classifier on a data with different weights of data points in each iteration it does\n",
    "    then sum up all those good classifiers to obtain one strong classifier over the data\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "The number of iterations (T) is what we call a hyper parameter:\n",
    "   - Its value differs from model to model and from problem to problem.\n",
    "   - Its value is not learnt by time, it is set by the programmer.\n",
    "   \n",
    "Suggest ways to select the optimal T keeping in mind that:\n",
    "   - If T is too big, the training time is large (you loop for T times, each time takes a model to fit and this model might take hours to fit)\n",
    "   - If T is too small, the boosting might not reach the best values it can get.\n",
    "   \n",
    "   \n",
    "\n",
    "**HINT**: Look at the graph of number of iterations vs performance and search for elbow method. Try to understand it and explain what it does.\\\n",
    "**HINT**: There are other hyper-parameter selection techniques, search for them as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Your answer:\\n    The elbow method is a common approach used for selecting the optimal number of weak classifiers (T) \\n    in the Adaboost algorithm. It involves plotting the performance of the Adaboost algorithm as a function \\n    of T and identifying the \"elbow\" point in the curve, which represents the point of diminishing returns where adding \\n    more weak classifiers does not significantly improve performance.\\n\\n    -- To use the elbow method you need to perform the following steps:\\n\\n    1: Train the Adaboost algorithm for different values of T, ranging from a small number to a large number.\\n\\n    2: Evaluate the performance of the Adaboost algorithm for each value of T using a suitable metric, such as \\n    accuracy, precision, recall, or F1 score.\\n\\n    3: Plot the performance of the Adaboost algorithm as a function of T, with T on the x-axis and performance on the y-axis.\\n\\n    4: Identify the elbow point in the curve, which represents the optimal value of T. \\n    The elbow point is typically the point where the curve starts to level off or plateau, indicating that \\n    adding more weak classifiers does not significantly improve performance.\\n\\n    5: Select the optimal value of T based on the elbow point and use this value to train the final Adaboost model.\\n\\n    6: The elbow method can be an effective and intuitive approach for selecting the optimal value of T in \\n    the Adaboost algorithm, especially when the performance metric is well-behaved and exhibits a clear elbow point. \\n    However, it may not always be applicable or suitable for more complex models or datasets. \\n    \\n    -------------------------------------------------------------------------------------------------------------------------------------------\\n    \\n    In the Adaboost algorithm, the main hyperparameters are the number of weak classifiers (T) and the learning rate (alpha).\\n    Here are some common hyperparameter selection techniques for the Adaboost algorithm:\\n\\n    1- Grid search: Grid search involves evaluating the performance of the Adaboost algorithm for a range of values of T \\n    and alpha and selecting the combination that gives the best performance. This approach can be time-consuming for large datasets \\n    or complex models, but it can be effective for smaller datasets or simpler models.\\n\\n    2- Random search: Random search involves randomly selecting values of T and alpha from a predefined range and evaluating the \\n    performance of the Adaboost algorithm for each combination. This approach can be less time-consuming than grid search and can \\n    be effective for larger datasets or more complex models.\\n\\n    3- Bayesian optimization: Bayesian optimization is a more advanced technique that involves constructing a probabilistic model \\n    of the objective function (i.e., the performance metric) and using it to search for the optimal hyperparameters. Bayesian optimization \\n    can be more efficient than grid search or random search, especially for high-dimensional hyperparameter spaces or expensive objective functions.\\n\\n    4- Learning curves: Learning curves show how the performance of the Adaboost algorithm improves with increasing amounts of data \\n    or increasing complexity. By analyzing the learning curves for different values of T and alpha, one can identify the optimal combination \\n    that maximizes performance without overfitting.\\n\\n    5- Cross-validation: Cross-validation involves dividing the data into multiple subsets, training the model on \\n    some subsets and evaluating it on the remaining subset. This process is repeated multiple times, and the average performance \\n    is used to select the optimal combination of T and alpha.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Your answer:\n",
    "    The elbow method is a common approach used for selecting the optimal number of weak classifiers (T) \n",
    "    in the Adaboost algorithm. It involves plotting the performance of the Adaboost algorithm as a function \n",
    "    of T and identifying the \"elbow\" point in the curve, which represents the point of diminishing returns where adding \n",
    "    more weak classifiers does not significantly improve performance.\n",
    "\n",
    "    -- To use the elbow method you need to perform the following steps:\n",
    "\n",
    "    1: Train the Adaboost algorithm for different values of T, ranging from a small number to a large number.\n",
    "\n",
    "    2: Evaluate the performance of the Adaboost algorithm for each value of T using a suitable metric, such as \n",
    "    accuracy, precision, recall, or F1 score.\n",
    "\n",
    "    3: Plot the performance of the Adaboost algorithm as a function of T, with T on the x-axis and performance on the y-axis.\n",
    "\n",
    "    4: Identify the elbow point in the curve, which represents the optimal value of T. \n",
    "    The elbow point is typically the point where the curve starts to level off or plateau, indicating that \n",
    "    adding more weak classifiers does not significantly improve performance.\n",
    "\n",
    "    5: Select the optimal value of T based on the elbow point and use this value to train the final Adaboost model.\n",
    "\n",
    "    6: The elbow method can be an effective and intuitive approach for selecting the optimal value of T in \n",
    "    the Adaboost algorithm, especially when the performance metric is well-behaved and exhibits a clear elbow point. \n",
    "    However, it may not always be applicable or suitable for more complex models or datasets. \n",
    "    \n",
    "    -------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    In the Adaboost algorithm, the main hyperparameters are the number of weak classifiers (T) and the learning rate (alpha).\n",
    "    Here are some common hyperparameter selection techniques for the Adaboost algorithm:\n",
    "\n",
    "    1- Grid search: Grid search involves evaluating the performance of the Adaboost algorithm for a range of values of T \n",
    "    and alpha and selecting the combination that gives the best performance. This approach can be time-consuming for large datasets \n",
    "    or complex models, but it can be effective for smaller datasets or simpler models.\n",
    "\n",
    "    2- Random search: Random search involves randomly selecting values of T and alpha from a predefined range and evaluating the \n",
    "    performance of the Adaboost algorithm for each combination. This approach can be less time-consuming than grid search and can \n",
    "    be effective for larger datasets or more complex models.\n",
    "\n",
    "    3- Bayesian optimization: Bayesian optimization is a more advanced technique that involves constructing a probabilistic model \n",
    "    of the objective function (i.e., the performance metric) and using it to search for the optimal hyperparameters. Bayesian optimization \n",
    "    can be more efficient than grid search or random search, especially for high-dimensional hyperparameter spaces or expensive objective functions.\n",
    "\n",
    "    4- Learning curves: Learning curves show how the performance of the Adaboost algorithm improves with increasing amounts of data \n",
    "    or increasing complexity. By analyzing the learning curves for different values of T and alpha, one can identify the optimal combination \n",
    "    that maximizes performance without overfitting.\n",
    "\n",
    "    5- Cross-validation: Cross-validation involves dividing the data into multiple subsets, training the model on \n",
    "    some subsets and evaluating it on the remaining subset. This process is repeated multiple times, and the average performance \n",
    "    is used to select the optimal combination of T and alpha.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
